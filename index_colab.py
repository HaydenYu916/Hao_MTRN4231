# -*- coding: utf-8 -*-
"""
RealSense Real-time Leaf Detection Program
Multi-leaf detection and analysis based on PlantCV

Features:
- Real-time image capture using RealSense camera
- Apply PlantCV for leaf segmentation and detection
- Real-time display of detection results and analysis data
- Support for saving detection results and annotated images
"""

# ============================================================================
# ğŸ“‹ Configuration Definition - Modify run mode here
# ============================================================================

# Select detection mode
FAST_MODE = True          # True=Fast mode(30+FPS), False=Precise mode(Low FPS but precise)

# ============================================================================
# Fine-grained Function Control - Choose which PlantCV analysis functions to enable
# ============================================================================
# Note: Each function can be independently enabled/disabled, combination can balance speed and accuracy

USE_SIZE_ANALYSIS = True      # Enable size analysis (consumption: medium)
USE_COLOR_ANALYSIS = False     # Enable color analysis (consumption: medium)
USE_MORPHOLOGY = True          # Enable morphological processing (consumption: low, recommended)
USE_CONTOUR_FILTERING = True   # Enable contour filtering (consumption: low, recommended)

# ============================================================================
# Other Configuration
# ============================================================================
SAVE_RESULTS = False       # True=Auto save results, False=Don't save
SAVE_INTERVAL = 5          # Save every N frames
OUTPUT_DIR = "./leaf_detection_results"

# ============================================================================
# Function Performance Impact Assessment
# ============================================================================
# USE_SIZE_ANALYSIS: â†“ Frame rate reduced by 15-20%
# USE_COLOR_ANALYSIS: â†“ Frame rate reduced by 15-20%
# Both enabled: â†“â†“ Frame rate reduced by 30-40%
# Both disabled: âœ“ Fastest speed (30+ FPS)
#
# Recommended configurations:
# ğŸš€ Ultra fast: Both disabled -> 30+ FPS
# âš–ï¸ Balanced: Only enable MORPHOLOGY -> 25+ FPS
# ğŸ¯ Precise: Both enabled -> 15-20 FPS
# ============================================================================

import sys
import warnings
import os

# Suppress PlantCV deprecation warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)

import cv2
import numpy as np
import pyrealsense2 as rs
from plantcv import plantcv as pcv
import json
from datetime import datetime
from collections import deque


class RealSenseLeafDetector:
    """
    Real-time leaf detector using RealSense camera and PlantCV
    """
    
    def __init__(self, output_dir="./leaf_detection_results", test_mode=False, fast_mode=True, 
                 use_size=False, use_color=False, use_morphology=True, use_filtering=True):
        """
        Initialize RealSense and PlantCV parameters
        
        Args:
            output_dir (str): Output results save directory
            test_mode (bool): Whether to use test mode
            fast_mode (bool): Fast mode
            use_size (bool): Enable size analysis
            use_color (bool): Enable color analysis
            use_morphology (bool): Enable morphological processing
            use_filtering (bool): Enable contour filtering
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        self.test_mode = test_mode
        self.fast_mode = fast_mode
        self.use_size = use_size
        self.use_color = use_color
        self.use_morphology = use_morphology
        self.use_filtering = use_filtering
        
        self.pipeline = None
        self.profile = None
        self.depth_scale = 0.001
        self.intrinsics = None
        self.align = None
        
        # Initialize PlantCV parameters
        pcv.params.debug = None
        pcv.params.text_size = 0.5
        pcv.params.text_thickness = 1
        
        # Detection results cache
        self.results_history = deque(maxlen=30)
        
        if test_mode:
            self._init_test_mode()
        else:
            self._init_realsense()
        
        # Print mode information
        print(f"ğŸ“Š Detection mode: {'âš¡ Fast mode' if self.fast_mode else 'ğŸ¯ Precise mode'}")
        print(f"ğŸ“Š Enabled functions:")
        print(f"   â€¢ Size analysis: {'âœ“' if self.use_size else 'âœ—'}")
        print(f"   â€¢ Color analysis: {'âœ“' if self.use_color else 'âœ—'}")
        print(f"   â€¢ Morphological processing: {'âœ“' if self.use_morphology else 'âœ—'}")
        print(f"   â€¢ Contour filtering: {'âœ“' if self.use_filtering else 'âœ—'}\n")
    
    def _init_realsense(self):
        """Initialize RealSense camera"""
        print("Attempting to connect to RealSense camera...")
        
        # Initialize RealSense pipeline
        self.pipeline = rs.pipeline()
        self.config = rs.config()
        
        # Try to detect available devices
        ctx = rs.context()
        devices = ctx.query_devices()
        
        if len(devices) == 0:
            print("âœ— No RealSense devices detected")
            print("  Please check:")
            print("  1. Is RealSense camera connected to USB")
            print("  2. Is librealsense driver installed")
            print("  3. Are USB permissions correct")
            raise RuntimeError("âŒ RealSense camera connection failed - no devices detected")
        
        print(f"âœ“ Detected {len(devices)} devices")
        
        # Configure RGB and depth streams
        try:
            self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
            self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        except Exception as e:
            print(f"âœ— Stream configuration failed: {e}")
            raise RuntimeError(f"âŒ RealSense stream configuration failed: {e}")
        
        # Start pipeline
        try:
            self.profile = self.pipeline.start(self.config)
        except Exception as e:
            print(f"âœ— Pipeline startup failed: {e}")
            raise RuntimeError(f"âŒ RealSense pipeline startup failed: {e}")
        
        # Get depth sensor
        depth_sensor = self.profile.get_device().first_depth_sensor()
        self.depth_scale = depth_sensor.get_depth_scale()
        
        # Create depth to RGB alignment object
        self.align = rs.align(rs.stream.color)
        
        # Get camera intrinsics
        color_profile = self.profile.get_stream(rs.stream.color)
        self.intrinsics = color_profile.as_video_stream_profile().get_intrinsics()
        
        print("âœ“ RealSense camera initialized")
        print(f"  Resolution: {self.intrinsics.width}x{self.intrinsics.height}")
        print(f"  Frame rate: 30 FPS")
        print(f"  Depth scale: {self.depth_scale}")
    
    def _init_test_mode(self):
        """åˆå§‹åŒ–æµ‹è¯•æ¨¡å¼ï¼ˆä¸éœ€è¦ç¡¬ä»¶ï¼‰"""
        print("âœ“ è¿›å…¥æµ‹è¯•æ¨¡å¼")
        print("  ä½¿ç”¨ç”Ÿæˆçš„æµ‹è¯•å›¾åƒ")
        self.test_mode = True
        self.test_frame_count = 0
    
    def capture_frame(self):
        """
        ä» RealSense ç›¸æœºæ•è·å½©è‰²å’Œæ·±åº¦å›¾åƒ
        
        Returns:
            tuple: (å½©è‰²å›¾åƒ, æ·±åº¦å›¾åƒ) æˆ– (None, None) å¦‚æœæ•è·å¤±è´¥
        """
        if self.test_mode:
            # æµ‹è¯•æ¨¡å¼ä¸‹ï¼Œä½¿ç”¨ç”Ÿæˆçš„æµ‹è¯•å›¾åƒ
            self.test_frame_count += 1
            if self.test_frame_count > 10:
                return None, None
            
            # ç”Ÿæˆä¸€ä¸ªå¸¦æœ‰ç»¿è‰²å¶å­ç‰¹å¾çš„æµ‹è¯•å›¾åƒ
            h, w = 480, 640
            img = np.zeros((h, w, 3), dtype=np.uint8)
            
            # ç™½è‰²èƒŒæ™¯
            img[:, :] = [200, 200, 200]
            
            # ç»˜åˆ¶æ¨¡æ‹Ÿçš„ç»¿è‰²æ¤ç‰©åŒºåŸŸ
            cv2.ellipse(img, (320, 240), (100, 80), 0, 0, 360, (50, 150, 50), -1)
            cv2.ellipse(img, (260, 200), (60, 50), 0, 0, 360, (60, 180, 60), -1)
            cv2.ellipse(img, (380, 200), (60, 50), 0, 0, 360, (60, 180, 60), -1)
            cv2.ellipse(img, (280, 300), (70, 60), 0, 0, 360, (40, 140, 40), -1)
            cv2.ellipse(img, (360, 300), (70, 60), 0, 0, 360, (40, 140, 40), -1)
            
            # æ·»åŠ æ–‡æœ¬æ ‡è®°
            cv2.putText(img, f"Test Frame {self.test_frame_count}", (w//2 - 120, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)
            cv2.putText(img, "Test Mode", (w//2 - 70, h-20), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
            
            # æ¨¡æ‹Ÿæ·±åº¦å›¾åƒ
            depth_img = np.ones((h, w), dtype=np.uint16) * 500
            
            return img, depth_img
        else:
            try:
                frames = self.pipeline.wait_for_frames()
                aligned_frames = self.align.process(frames)
                
                color_frame = aligned_frames.get_color_frame()
                depth_frame = aligned_frames.get_depth_frame()
                
                if not color_frame or not depth_frame:
                    return None, None
                
                color_image = np.asanyarray(color_frame.get_data())
                depth_image = np.asanyarray(depth_frame.get_data())
                
                return color_image, depth_image
            except Exception as e:
                print(f"âœ— æ•è·å›¾åƒå¤±è´¥: {e}")
                return None, None
    
    def preprocess_image(self, img):
        """
        é¢„å¤„ç†å›¾åƒï¼šè£å‰ªã€æ—‹è½¬ã€è‰²å½©æ ¡æ­£
        
        Args:
            img: è¾“å…¥ BGR å›¾åƒ
            
        Returns:
            é¢„å¤„ç†åçš„å›¾åƒ
        """
        # è£å‰ªå›¾åƒ (å¯é€‰)
        h, w = img.shape[:2]
        crop_img = pcv.crop(img=img, x=50, y=50, h=h-100, w=w-100)
        
        # æ—‹è½¬ï¼ˆå¦‚éœ€è¦        rotate_img = pcv.transform.rotate(crop_img, 0, False)
        
        # è‰²å½©æ ¡æ­£ï¼ˆå¦‚æœå¤±è´¥ï¼Œä½¿ç”¨åŸå›¾ï¼‰
        try:
            corrected_img = pcv.transform.auto_correct_color(rgb_img=rotate_img)
        except:
            corrected_img = rotate_img
        
        return corrected_img
    
    def detect_leaves(self, img):
        """
        æ£€æµ‹å¶å­å¹¶è¿›è¡Œåˆ†æï¼ˆä¼˜åŒ–ç‰ˆæœ¬ä»¥æé«˜å¸§ç‡ï¼‰
        
        Args:
            img: è¾“å…¥ BGR å›¾åƒ
            
        Returns:
            dict: åŒ…å«æ£€æµ‹ç»“æœå’Œåˆ†ææ•°æ®
        """
        try:
            # å¿«é€Ÿå¤„ç†ï¼šè·³è¿‡è‰²å½©æ ¡æ­£ä»¥èŠ‚çœæ—¶é—´
            h, w = img.shape[:2]
            
            # åªåšæœ€å°çš„è£å‰ªï¼ˆå‡å°‘è®¡ç®—ï¼‰
            crop_img = pcv.crop(img=img, x=20, y=20, h=h-40, w=w-40)
            
            # å¿«é€Ÿé¢œè‰²æ£€æµ‹ - ç›´æ¥ä½¿ç”¨ HSVï¼ˆè·³è¿‡è‰²å½©æ ¡æ­£ï¼‰
            hsv = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)
            
            # æ›´ä¸¥æ ¼çš„ç»¿è‰²èŒƒå›´ï¼ˆè¿‡æ»¤æ‰é»‘è‰²å’Œå…¶ä»–éæ¤ç‰©ç‰©ä½“ï¼‰
            # H: 35-85 (ç»¿è‰²), S: 50-255 (é¥±å’Œåº¦æ›´é«˜), V: 60-255 (äº®åº¦)
            lower_green = np.array([35, 50, 60])
            upper_green = np.array([85, 255, 255])
            thresh = cv2.inRange(hsv, lower_green, upper_green)
            thresh = (thresh / 255).astype(np.uint8)
            
            # å¿«é€Ÿå½¢æ€å­¦å¤„ç†ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            if self.use_morphology:
                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
                thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)
                thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)
            
            # è½®å»“æ£€æµ‹ï¼ˆæ¯” PlantCV çš„æ–¹æ³•å¿«ï¼‰
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # è½®å»“è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
            if self.use_filtering:
                # ä¸¥æ ¼çš„è¿‡æ»¤æ¡ä»¶
                valid_contours = []
                min_area = 500      # æœ€å°é¢ç§¯ï¼ˆè¿‡æ»¤å¤ªå°çš„å™ªå£°ï¼‰
                max_area = 50000    # æœ€å¤§é¢ç§¯ï¼ˆè¿‡æ»¤èƒŒæ™¯ï¼‰
                min_circularity = 0.3  # æœ€å°åœ†å½¢åº¦
                
                for cnt in contours:
                    area = cv2.contourArea(cnt)
                    
                    # è¿‡æ»¤é¢ç§¯
                    if area < min_area or area > max_area:
                        continue
                    
                    # è®¡ç®—åœ†å½¢åº¦
                    perimeter = cv2.arcLength(cnt, True)
                    if perimeter == 0:
                        continue
                        
                    circularity = 4 * np.pi * area / (perimeter * perimeter)
                    if circularity < min_circularity:
                        continue
                    
                    # æ£€æŸ¥å®½é«˜æ¯”
                    x, y, w_rect, h_rect = cv2.boundingRect(cnt)
                    if w_rect == 0 or h_rect == 0:
                        continue
                        
                    aspect_ratio = float(w_rect) / h_rect
                    if aspect_ratio < 0.3 or aspect_ratio > 3.0:
                        continue
                    
                    valid_contours.append(cnt)
            else:
                # ä¸è¿‡æ»¤ï¼Œåªåšæœ€å°é¢ç§¯æ£€æŸ¥
                valid_contours = [c for c in contours if cv2.contourArea(c) > 100]
            
            n_obj = len(valid_contours)
            
            # åˆ›å»ºæ ‡è®°å›¾åƒ
            labeled_objects = np.zeros_like(thresh)
            leaf_coordinates = []  # å­˜å‚¨æ‰€æœ‰å¶å­çš„åæ ‡
            
            for idx, cnt in enumerate(valid_contours, 1):
                cv2.drawContours(labeled_objects, [cnt], 0, idx, -1)
                
                # è®¡ç®—å¶å­çš„åæ ‡ä¿¡æ¯
                x, y, w_rect, h_rect = cv2.boundingRect(cnt)
                M = cv2.moments(cnt)
                
                # è®¡ç®—ä¸­å¿ƒç‚¹
                if M['m00'] > 0:
                    cx = int(M['m10'] / M['m00'])
                    cy = int(M['m01'] / M['m00'])
                else:
                    cx = x + w_rect // 2
                    cy = y + h_rect // 2
                
                # è®¡ç®—é¢ç§¯å’Œå‘¨é•¿
                area = cv2.contourArea(cnt)
                perimeter = cv2.arcLength(cnt, True)
                
                # ä¿å­˜å¶å­ä¿¡æ¯
                leaf_info = {
                    'id': idx,
                    'center': {'x': cx, 'y': cy},  # ä¸­å¿ƒç‚¹åæ ‡
                    'bounding_box': {  # è¾¹ç•Œæ¡†åæ ‡
                        'x': x,
                        'y': y,
                        'width': w_rect,
                        'height': h_rect,
                        'x_min': x,
                        'y_min': y,
                        'x_max': x + w_rect,
                        'y_max': y + h_rect
                    },
                    'area': float(area),  # é¢ç§¯
                    'perimeter': float(perimeter),  # å‘¨é•¿
                }
                leaf_coordinates.append(leaf_info)
            
            # å¯é€‰ï¼šPlantCV åˆ†æåŠŸèƒ½
            analysis_results = {}
            if (self.use_size or self.use_color) and len(valid_contours) > 0:
                try:
                    if self.use_size:
                        # å¤§å°åˆ†æ
                        size_analysis = pcv.analyze.size(
                            img=crop_img,
                            labeled_mask=labeled_objects,
                            n_labels=len(valid_contours)
                        )
                        analysis_results['size'] = size_analysis
                except:
                    pass
                
                try:
                    if self.use_color:
                        # é¢œè‰²åˆ†æ
                        color_analysis = pcv.analyze.color(
                            rgb_img=crop_img,
                            labeled_mask=labeled_objects,
                            n_labels=len(valid_contours),
                            colorspaces='hsv'
                        )
                        analysis_results['color'] = color_analysis
                except:
                    pass
            
            # è·å–æ£€æµ‹ç»“æœ
            results = {
                'timestamp': datetime.now().isoformat(),
                'num_leaves': n_obj,
                'processed_image': crop_img,
                'mask': thresh,
                'labeled_objects': labeled_objects,
                'contours': valid_contours,
                'analysis': analysis_results,
                'outputs': pcv.outputs.observations if (self.use_size or self.use_color) else {},
                'leaf_coordinates': leaf_coordinates # æ·»åŠ å¶å­åæ ‡ä¿¡æ¯
            }
            
            return results
            
        except Exception as e:
            print(f"âœ— å¶å­æ£€æµ‹å¤±è´¥: {e}")
            return None
    
    def draw_results(self, img, results):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
        
        Args:
            img: åŸå§‹ BGR å›¾åƒ
            results: æ£€æµ‹ç»“æœå­—å…¸
            
        Returns:
            æ ‡æ³¨åçš„å›¾åƒ
        """
        if results is None:
            return img
        
        annotated_img = img.copy()
        h, w = annotated_img.shape[:2]
        
        # ç»˜åˆ¶æ–‡æœ¬ä¿¡æ¯
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        thickness = 2
        text_color = (0, 255, 0)
        
        y_offset = 30
        cv2.putText(annotated_img, f"Detected Leaves: {results['num_leaves']}", 
                    (10, y_offset), font, font_scale, text_color, thickness)
        
        # æ˜¾ç¤ºæ—¶é—´æˆ³
        cv2.putText(annotated_img, f"Time: {results['timestamp'][-8:]}", 
                    (10, y_offset + 30), font, font_scale, text_color, thickness)
        
        # æ˜¾ç¤ºå¶å­åæ ‡ä¿¡æ¯ï¼ˆåœ¨æ§åˆ¶å°æ‰“å°ï¼Œä¸åœ¨å›¾åƒä¸Šæ˜¾ç¤ºä»¥å…è¿‡æ‹¥æŒ¤ï¼‰
        if results.get('leaf_coordinates'):
            print(f"\nğŸ“ å¶å­åæ ‡ä¿¡æ¯ (å¸§ {results.get('frame_id', 'N/A')}):")
            for leaf in results['leaf_coordinates']:
                print(f"   Leaf {leaf['id']}: ä¸­å¿ƒ=({leaf['center']['x']}, {leaf['center']['y']}), "
                      f"é¢ç§¯={leaf['area']:.0f}, å‘¨é•¿={leaf['perimeter']:.1f}")
        
        return annotated_img
    
    def save_results(self, img, results, frame_id):
        """
        ä¿å­˜æ£€æµ‹ç»“æœå’Œæ ‡æ³¨å›¾åƒ
        
        Args:
            img: åŸå§‹å›¾åƒ
            results: æ£€æµ‹ç»“æœ
            frame_id: å¸§ç¼–å·
        """
        if results is None:
            return
        
        try:
            # ä¿å­˜æ ‡æ³¨å›¾åƒ
            annotated_img = self.draw_results(img, results)
            img_path = os.path.join(self.output_dir, f"annotated_{frame_id:04d}.jpg")
            cv2.imwrite(img_path, annotated_img)
            
            # ä¿å­˜æ©è†œ
            mask_path = os.path.join(self.output_dir, f"mask_{frame_id:04d}.jpg")
            cv2.imwrite(mask_path, results['mask'] * 255)
            
            # ä¿å­˜è¯¦ç»†ç»“æœä¸º JSONï¼ˆåŒ…å«åæ ‡ï¼‰
            json_results = {
                'frame_id': frame_id,
                'timestamp': results['timestamp'],
                'num_leaves': results['num_leaves'],
                'leaf_coordinates': results.get('leaf_coordinates', [])  # åŒ…å«æ‰€æœ‰åæ ‡
            }
            
            json_path = os.path.join(self.output_dir, f"results_{frame_id:04d}.json")
            with open(json_path, 'w') as f:
                json.dump(json_results, f, indent=2)
                
        except Exception as e:
            print(f"âœ— ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def run(self, save_interval=10):
        """
        ä¸»å¾ªç¯ï¼šå®æ—¶å¤„ç†è§†é¢‘æµ
        
        Args:
            save_interval (int): æ¯éš”å¤šå°‘å¸§ä¿å­˜ä¸€æ¬¡ç»“æœ
        """
        frame_count = 0
        
        print("\nå¼€å§‹å®æ—¶å¶å­æ£€æµ‹...")
        print("æŒ‰ 'q' é”®é€€å‡ºï¼ŒæŒ‰ 's' é”®ä¿å­˜å½“å‰å¸§\n")
        
        try:
            while True:
                # æ•è·å›¾åƒ
                color_image, depth_image = self.capture_frame()
                if color_image is None:
                    continue
                
                frame_count += 1
                
                # æ£€æµ‹å¶å­
                results = self.detect_leaves(color_image)
                
                # ç»˜åˆ¶ç»“æœ
                display_img = self.draw_results(color_image, results)
                
                # æ˜¾ç¤ºå¤„ç†åçš„æ ‡æ³¨å›¾åƒï¼ˆè€Œä¸æ˜¯æ©è†œï¼‰
                if results is not None:
                    # åœ¨å¤„ç†åçš„å›¾åƒä¸Šç»˜åˆ¶æ ‡æ³¨
                    annotated_img = self._draw_annotations(results['processed_image'], results)
                    
                    # è°ƒæ•´å°ºå¯¸ä»¥åŒ¹é…display_img
                    h_display, w_display = display_img.shape[:2]
                    h_annot, w_annot = annotated_img.shape[:2]
                    
                    if h_annot != h_display or w_annot != w_display:
                        annotated_img = cv2.resize(annotated_img, (w_display, h_display))
                    
                    # åˆå¹¶å›¾åƒ
                    combined = np.hstack([display_img, annotated_img])
                else:
                    combined = display_img
                
                # æ˜¾ç¤ºå®æ—¶ç»“æœ
                cv2.imshow('RealSense Leaf Detection', combined)
                
                # å®šæœŸä¿å­˜ç»“æœ
                if save_interval > 0 and frame_count % save_interval == 0 and results is not None:
                    self.save_results(color_image, results, frame_count)
                    print(f"âœ“ å¸§ {frame_count}: {results['num_leaves']} ç‰‡å¶å­æ£€æµ‹åˆ°")
                
                # é”®ç›˜æ§åˆ¶
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("\né€€å‡ºç¨‹åº...")
                    break
                elif key == ord('s'):
                    self.save_results(color_image, results, frame_count)
                    print(f"âœ“ ä¿å­˜å½“å‰å¸§ {frame_count}")
        
        except KeyboardInterrupt:
            print("\nè¢«ç”¨æˆ·ä¸­æ–­")
        finally:
            self.cleanup()
    
    def _draw_annotations(self, img, results):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶å¶å­æ ‡æ³¨ï¼ˆè¾¹ç•Œæ¡†å’Œæ ‡ç­¾ï¼‰
        
        Args:
            img: è¾“å…¥å›¾åƒ
            results: æ£€æµ‹ç»“æœ
            
        Returns:
            æ ‡æ³¨åçš„å½©è‰²å›¾åƒ
        """
        annotated = img.copy()
        
        if results is None or 'contours' not in results:
            return annotated
        
        contours = results['contours']
        
        # ä¸ºæ¯ä¸ªæ£€æµ‹åˆ°çš„å¯¹è±¡ç»˜åˆ¶ä¸åŒé¢œè‰²çš„æ ‡è®°
        colors = [
            (255, 0, 0),
            (0, 255, 0),
            (0, 0, 255),
            (255, 255, 0),
            (255, 0, 255),
            (0, 255, 255),
        ]
        
        try:
            # ä¸ºæ¯ä¸ªè½®å»“ç»˜åˆ¶æ ‡æ³¨
            for obj_id, cnt in enumerate(contours, 1):
                color = colors[(obj_id - 1) % len(colors)]
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                x, y, w, h = cv2.boundingRect(cnt)
                cv2.rectangle(annotated, (x, y), (x + w, y + h), color, 2)
                
                # ç»˜åˆ¶æ ‡ç­¾
                cv2.putText(annotated, f'Leaf {obj_id}', (x, y - 5),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                
                # ç»˜åˆ¶ä¸­å¿ƒç‚¹
                M = cv2.moments(cnt)
                if M['m00'] > 0:
                    cx = int(M['m10'] / M['m00'])
                    cy = int(M['m01'] / M['m00'])
                    cv2.circle(annotated, (cx, cy), 5, color, -1)
        except Exception as e:
            pass
        
        return annotated
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("\næ¸…ç†èµ„æº...")
        if self.pipeline:
            self.pipeline.stop()
        cv2.destroyAllWindows()
        print("âœ“ ç¨‹åºæ­£å¸¸é€€å‡º")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("RealSense å®æ—¶å¶å­æ£€æµ‹ç³»ç»Ÿ")
    print("åŸºäº PlantCV çš„å¤šå¶æ£€æµ‹å’Œåˆ†æ")
    print("=" * 60)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print(f"\nâš™ï¸  å½“å‰é…ç½®:")
    print(f"   â€¢ æ£€æµ‹æ¨¡å¼: {'âš¡ å¿«é€Ÿ (30+ FPS)' if FAST_MODE else 'ğŸ¯ ç²¾ç¡® (10-15 FPS)'}")
    print(f"   â€¢ å¤§å°åˆ†æ: {'âœ“ å¯ç”¨' if USE_SIZE_ANALYSIS else 'âœ— ç¦ç”¨'}")
    print(f"   â€¢ é¢œè‰²åˆ†æ: {'âœ“ å¯ç”¨' if USE_COLOR_ANALYSIS else 'âœ— ç¦ç”¨'}")
    print(f"   â€¢ å½¢æ€å­¦å¤„ç†: {'âœ“ å¯ç”¨' if USE_MORPHOLOGY else 'âœ— ç¦ç”¨'}")
    print(f"   â€¢ è½®å»“è¿‡æ»¤: {'âœ“ å¯ç”¨' if USE_CONTOUR_FILTERING else 'âœ— ç¦ç”¨'}")
    print(f"   â€¢ ä¿å­˜ç»“æœ: {'âœ“ å¯ç”¨' if SAVE_RESULTS else 'âœ— ç¦ç”¨'}")
    print(f"   â€¢ ä¿å­˜é—´éš”: æ¯ {SAVE_INTERVAL} å¸§")
    print(f"   â€¢ è¾“å‡ºç›®å½•: {OUTPUT_DIR}\n")
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = RealSenseLeafDetector(
        output_dir=OUTPUT_DIR,
        fast_mode=FAST_MODE,
        use_size=USE_SIZE_ANALYSIS,
        use_color=USE_COLOR_ANALYSIS,
        use_morphology=USE_MORPHOLOGY,
        use_filtering=USE_CONTOUR_FILTERING
    )
    
    # è¿è¡Œå®æ—¶æ£€æµ‹
    save_interval = SAVE_INTERVAL if SAVE_RESULTS else 0
    detector.run(save_interval=save_interval)


if __name__ == "__main__":
    main()
